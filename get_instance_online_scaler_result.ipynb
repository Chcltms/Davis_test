{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "from deeplab_resnet import DeepLabv3_plus\n",
    "from copy import deepcopy\n",
    "import concurrent.futures\n",
    "import time\n",
    "import glob\n",
    "import sys\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = [0,1,3,4]\n",
    "with open('val_v_5.json','r') as f:\n",
    "    val_file = json.load(f)\n",
    "val_file = json.loads(val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_dismap(dismap, bbox):\n",
    "    x_min, y_min, x_max, y_max = bbox[:]\n",
    "\n",
    "    # draw bounding box\n",
    "    cv2.line(dismap, (x_min, y_min), (x_max, y_min), color=1, thickness=1)\n",
    "    cv2.line(dismap, (x_min, y_min), (x_min, y_max), color=1, thickness=1)\n",
    "    cv2.line(dismap, (x_max, y_max), (x_max, y_min), color=1, thickness=1)\n",
    "    cv2.line(dismap, (x_max, y_max), (x_min, y_max), color=1, thickness=1)\n",
    "\n",
    "    tmp = (dismap > 0).astype(np.uint8) # mark boundary\n",
    "    tmp_ = deepcopy(tmp)\n",
    "\n",
    "    fill_mask = np.ones((tmp.shape[0] + 2, tmp.shape[1] + 2)).astype(np.uint8)\n",
    "    fill_mask[1:-1, 1:-1] = tmp_\n",
    "    cv2.floodFill(tmp_, fill_mask, (int((x_min + x_max) / 2), int((y_min + y_max) / 2)), 5) # fill pixel inside bounding box\n",
    "\n",
    "    tmp_ = tmp_.astype(np.int8)\n",
    "    tmp_[tmp_ == 5] = -1 # pixel inside bounding box\n",
    "    tmp_[tmp_ == 0] = 1 # pixel on and outside bounding box\n",
    "\n",
    "    tmp = (tmp == 0).astype(np.uint8)\n",
    "\n",
    "    dismap = cv2.distanceTransform(tmp, cv2.DIST_L2, cv2.DIST_MASK_PRECISE)  # compute distance inside and outside bounding box\n",
    "    dismap = tmp_ * dismap + 128\n",
    "\n",
    "    dismap[dismap > 255] = 255\n",
    "    dismap[dismap < 0] = 0\n",
    "\n",
    "    dismap = dismap.astype(np.uint8)\n",
    "\n",
    "    return dismap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_map(mask,bbox):\n",
    "    bounds = (0, 0, mask.shape[1] - 1, mask.shape[0] - 1)\n",
    "\n",
    "\n",
    "    x_min = max(bbox[0], bounds[0])\n",
    "    y_min = max(bbox[1], bounds[1])\n",
    "    x_max = min(bbox[2], bounds[2])\n",
    "    y_max = min(bbox[3], bounds[3])\n",
    "\n",
    "    bbox = [x_min, y_min, x_max, y_max]\n",
    "\n",
    "    dismap = np.zeros((mask.shape[0], mask.shape[1]))\n",
    "    dismap = compute_dismap(dismap, bbox)\n",
    "    return dismap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(model_name):\n",
    "    net = DeepLabv3_plus(n_classes=1, nInputChannels=4)\n",
    "    checkpoint = torch.load(model_name, map_location=lambda storage, loc: storage)\n",
    "    pretrained_dict = {k: v for k, v in checkpoint.items() if k in net.state_dict()}\n",
    "    model_dict = net.state_dict()\n",
    "    model_dict.update(pretrained_dict)\n",
    "    net.load_state_dict(model_dict)\n",
    "    net.eval()\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_prediction(Resume_flag, Resume_box,outputs,result_shape, mask_dir, img_path, thres=0.75):\n",
    "    prediction = np.transpose(outputs.data.numpy()[0, ...], (1, 2, 0))\n",
    "    prediction = 1 / (1 + np.exp(-prediction))\n",
    "    prediction = np.squeeze(prediction)\n",
    "    prediction[prediction>thres] = 255\n",
    "    prediction[prediction<=thres] = 0\n",
    "    prediction = prediction.astype(np.uint8)\n",
    "    if Resume_flag:\n",
    "        x_min_re, y_min_re, x_max_re, y_max_re = Resume_box\n",
    "        h = y_max_re - y_min_re\n",
    "        w = x_max_re - x_min_re\n",
    "        temp = np.zeros((result_shape[0],result_shape[1]))\n",
    "        prediction = cv2.resize(prediction, (w, h),interpolation=cv2.INTER_NEAREST)\n",
    "        temp[y_min_re : y_max_re, x_min_re : x_max_re] = prediction\n",
    "        prediction = temp\n",
    "    else:\n",
    "        prediction = cv2.resize(prediction, (result_shape[1], result_shape[0]),interpolation=cv2.INTER_NEAREST)\n",
    "    result_path  = os.path.join(mask_dir, img_path.split('/')[-1].replace('.jpg', '.png'))\n",
    "    cv2.imwrite(result_path, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Refine_bbox(result_shape, bbox, img):\n",
    "    x_min, y_min, x_max, y_max = bbox[:]\n",
    "    mask_area = result_shape[0] * result_shape[1]\n",
    "    h = y_max - y_min\n",
    "    w = x_max - x_min\n",
    "    instance_area = h * w\n",
    "    if instance_area/mask_area < 0.4:\n",
    "        y_border = result_shape[0]-1\n",
    "        x_border = result_shape[1]-1\n",
    "        y_min_re = max(0,y_min-h)\n",
    "        y_max_re = min(y_max+h, y_border)\n",
    "        x_min_re = max(0,x_min-w)\n",
    "        x_max_re = min(x_max+w, x_border)\n",
    "        img_re = img[y_min_re : y_max_re, x_min_re : x_max_re]\n",
    "        return True,[x_min_re, y_min_re, x_max_re, y_max_re],[x_min-x_min_re, y_min-y_min_re, x_max - x_min_re, y_max - y_min_re], img_re\n",
    "    else:\n",
    "        return False,[1,1,1,1],bbox, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_prepare(img_re, bbox_re):\n",
    "    dis_map = distance_map(img_re, bbox_re)\n",
    "    dis_map = cv2.resize(dis_map, (450, 450), interpolation=cv2.INTER_NEAREST)\n",
    "    dis_map = dis_map[:,:, np.newaxis]\n",
    "    res = cv2.resize(img_re, (450,450), interpolation=cv2.INTER_CUBIC)\n",
    "    res = cv2.cvtColor(res, cv2.COLOR_BGR2RGB)\n",
    "    res = np.concatenate((res, dis_map), axis=2)\n",
    "    res = res.transpose((2,0,1))\n",
    "    res = res[np.newaxis,:,:,:]\n",
    "    res = torch.from_numpy(res).float()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_val_result_with_scaler(sample):\n",
    "    select_model_path, key, category = sample\n",
    "    net = model_load(select_model_path)\n",
    "    print('models have been loaded!')\n",
    "    base_dir = '/home/ningxinL/DeepGrabCut_Davis_val/result/ds_val_finetune_scaler_v_5/'\n",
    "    if not os.path.exists(base_dir):\n",
    "        os.mkdir(base_dir)\n",
    "        print('/home/ningxinL/DeepGrabCut_Davis_val/result/ds_val_finetune_scaler_v_5/ make successfully!')\n",
    "    result_dir = os.path.join(base_dir, key)\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.mkdir(result_dir)\n",
    "    temp = val_file[key]\n",
    "    for frame in temp:\n",
    "        img_path = temp[frame]['img_path']\n",
    "        img = cv2.imread(img_path)\n",
    "        result_shape = img.shape\n",
    "        mask_area = result_shape[0] * result_shape[1]\n",
    "        if category in temp[frame].keys():\n",
    "            mask_dir = os.path.join(result_dir, category)\n",
    "            if not os.path.exists(mask_dir):\n",
    "                os.mkdir(mask_dir)\n",
    "            bbox = temp[frame][category]['bbox']\n",
    "            Resume_flag, Resume_box, bbox_re, img_re = Refine_bbox(result_shape, bbox, img)\n",
    "            res = input_prepare(img_re, bbox_re)\n",
    "            outputs = net.forward(res)\n",
    "            outputs = outputs.to(torch.device('cpu'))\n",
    "            save_prediction(Resume_flag, Resume_box,outputs,result_shape, mask_dir, img_path, thres=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 0\n",
    "base_dir = '/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/'\n",
    "sample_list = []\n",
    "for root,directions, files in os.walk(base_dir):\n",
    "    for direction in directions:\n",
    "        try:\n",
    "            category, instance_num = direction.split('_')\n",
    "        except:\n",
    "            continue\n",
    "        num +=1\n",
    "        model_list = glob.glob(os.path.join(base_dir, direction)+'/*.pth')\n",
    "        max_epoch_num = 0\n",
    "        for model_path in model_list:\n",
    "            epoch_num = int((model_path.split('-')[-1]).split('_')[0])\n",
    "            if epoch_num > max_epoch_num:\n",
    "                max_epoch_num = epoch_num\n",
    "                select_model_path = model_path\n",
    "        sample = [select_model_path, category, instance_num]\n",
    "        sample_list.append(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/india_1/deepgc_epoch-11_davis_finetune.pth',\n",
       "  'india',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/gold-fish_3/deepgc_epoch-9_davis_finetune.pth',\n",
       "  'gold-fish',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/drift-chicane_1/deepgc_epoch-11_davis_finetune.pth',\n",
       "  'drift-chicane',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/gold-fish_2/deepgc_epoch-12_davis_finetune.pth',\n",
       "  'gold-fish',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/india_2/deepgc_epoch-22_davis_finetune.pth',\n",
       "  'india',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/gold-fish_5/deepgc_epoch-15_davis_finetune.pth',\n",
       "  'gold-fish',\n",
       "  '5'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/shooting_3/deepgc_epoch-5_davis_finetune.pth',\n",
       "  'shooting',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/shooting_3/deepgc_epoch-5_davis_finetune.pth',\n",
       "  'judo',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/judo_2/deepgc_epoch-23_davis_finetune.pth',\n",
       "  'judo',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/paragliding-launch_1/deepgc_epoch-13_davis_finetune.pth',\n",
       "  'paragliding-launch',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/paragliding-launch_3/deepgc_epoch-8_davis_finetune.pth',\n",
       "  'paragliding-launch',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/shooting_1/deepgc_epoch-20_davis_finetune.pth',\n",
       "  'shooting',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/motocross-jump_2/deepgc_epoch-17_davis_finetune.pth',\n",
       "  'motocross-jump',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/lab-coat_1/deepgc_epoch-68_davis_finetune.pth',\n",
       "  'lab-coat',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/bmx-trees_1/deepgc_epoch-18_davis_finetune.pth',\n",
       "  'bmx-trees',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/horsejump-high_2/deepgc_epoch-14_davis_finetune.pth',\n",
       "  'horsejump-high',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/soapbox_2/deepgc_epoch-27_davis_finetune.pth',\n",
       "  'soapbox',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/parkour_1/deepgc_epoch-24_davis_finetune.pth',\n",
       "  'parkour',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/loading_3/deepgc_epoch-18_davis_finetune.pth',\n",
       "  'loading',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/loading_3/deepgc_epoch-18_davis_finetune.pth',\n",
       "  'kite-surf',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/lab-coat_2/deepgc_epoch-46_davis_finetune.pth',\n",
       "  'lab-coat',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/mbike-trick_1/deepgc_epoch-17_davis_finetune.pth',\n",
       "  'mbike-trick',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/bike-packing_1/deepgc_epoch-41_davis_finetune.pth',\n",
       "  'bike-packing',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/gold-fish_1/deepgc_epoch-15_davis_finetune.pth',\n",
       "  'gold-fish',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/paragliding-launch_2/deepgc_epoch-9_davis_finetune.pth',\n",
       "  'paragliding-launch',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/scooter-black_1/deepgc_epoch-14_davis_finetune.pth',\n",
       "  'scooter-black',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/gold-fish_4/deepgc_epoch-15_davis_finetune.pth',\n",
       "  'gold-fish',\n",
       "  '4'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/lab-coat_3/deepgc_epoch-14_davis_finetune.pth',\n",
       "  'lab-coat',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/goat_1/deepgc_epoch-13_davis_finetune.pth',\n",
       "  'goat',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/cows_1/deepgc_epoch-15_davis_finetune.pth',\n",
       "  'cows',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/car-roundabout_1/deepgc_epoch-14_davis_finetune.pth',\n",
       "  'car-roundabout',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/dogs-jump_1/deepgc_epoch-8_davis_finetune.pth',\n",
       "  'dogs-jump',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/lab-coat_4/deepgc_epoch-20_davis_finetune.pth',\n",
       "  'lab-coat',\n",
       "  '4'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/breakdance_1/deepgc_epoch-12_davis_finetune.pth',\n",
       "  'breakdance',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/blackswan_1/deepgc_epoch-11_davis_finetune.pth',\n",
       "  'blackswan',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/scooter-black_2/deepgc_epoch-15_davis_finetune.pth',\n",
       "  'scooter-black',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/soapbox_1/deepgc_epoch-15_davis_finetune.pth',\n",
       "  'soapbox',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/dogs-jump_2/deepgc_epoch-12_davis_finetune.pth',\n",
       "  'dogs-jump',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/dance-twirl_1/deepgc_epoch-24_davis_finetune.pth',\n",
       "  'dance-twirl',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/kite-surf_1/deepgc_epoch-8_davis_finetune.pth',\n",
       "  'kite-surf',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/horsejump-high_1/deepgc_epoch-14_davis_finetune.pth',\n",
       "  'horsejump-high',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/loading_2/deepgc_epoch-18_davis_finetune.pth',\n",
       "  'loading',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/libby_1/deepgc_epoch-8_davis_finetune.pth',\n",
       "  'libby',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/camel_1/deepgc_epoch-15_davis_finetune.pth',\n",
       "  'camel',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/soapbox_3/deepgc_epoch-19_davis_finetune.pth',\n",
       "  'soapbox',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/bike-packing_2/deepgc_epoch-14_davis_finetune.pth',\n",
       "  'bike-packing',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/bmx-trees_2/deepgc_epoch-13_davis_finetune.pth',\n",
       "  'bmx-trees',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/motocross-jump_1/deepgc_epoch-12_davis_finetune.pth',\n",
       "  'motocross-jump',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/shooting_2/deepgc_epoch-26_davis_finetune.pth',\n",
       "  'shooting',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/drift-straight_1/deepgc_epoch-14_davis_finetune.pth',\n",
       "  'drift-straight',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/loading_1/deepgc_epoch-14_davis_finetune.pth',\n",
       "  'loading',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/pigs_1/deepgc_epoch-16_davis_finetune.pth',\n",
       "  'pigs',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/car-shadow_1/deepgc_epoch-11_davis_finetune.pth',\n",
       "  'car-shadow',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/pigs_3/deepgc_epoch-13_davis_finetune.pth',\n",
       "  'pigs',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/india_3/deepgc_epoch-17_davis_finetune.pth',\n",
       "  'india',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/mbike-trick_2/deepgc_epoch-15_davis_finetune.pth',\n",
       "  'mbike-trick',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/lab-coat_5/deepgc_epoch-19_davis_finetune.pth',\n",
       "  'lab-coat',\n",
       "  '5'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/kite-surf_2/deepgc_epoch-8_davis_finetune.pth',\n",
       "  'kite-surf',\n",
       "  '2'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/dog_1/deepgc_epoch-12_davis_finetune.pth',\n",
       "  'dog',\n",
       "  '1'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/dogs-jump_3/deepgc_epoch-10_davis_finetune.pth',\n",
       "  'dogs-jump',\n",
       "  '3'],\n",
       " ['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/pigs_2/deepgc_epoch-16_davis_finetune.pth',\n",
       "  'pigs',\n",
       "  '2']]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Constructing DeepLabv3+ model...\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of classes: 1\n",
      "Constructing DeepLabv3+ model...\n",
      "Output stride: 16\n",
      "Constructing DeepLabv3+ model...\n",
      "Constructing DeepLabv3+ model...\n",
      "Output stride: 16\n",
      "Constructing DeepLabv3+ model...\n",
      "Constructing DeepLabv3+ model...\n",
      "Constructing DeepLabv3+ model...\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of Input Channels: 4\n",
      "Number of Input Channels: 4\n",
      "Number of Input Channels: 4\n",
      "Number of classes: 1\n",
      "Number of classes: 1\n",
      "Number of classes: 1\n",
      "Constructing DeepLabv3+ model...\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Output stride: 16\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of classes: 1\n",
      "Number of Input Channels: 4\n",
      "Output stride: 16\n",
      "Number of classes: 1\n",
      "Number of Input Channels: 4\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Output stride: 16\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Number of Input Channels: 4\n",
      "Number of Input Channels: 4\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models have been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models have been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Constructing DeepLabv3+ model...\n",
      "Output stride: 16\n",
      "Number of classes: 1\n",
      "Number of Input Channels: 4\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n",
      "models have been loaded!\n"
     ]
    }
   ],
   "source": [
    "with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "        executor.map(get_val_result_with_scaler, sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing DeepLabv3+ model...\n",
      "Number of classes: 1\n",
      "Output stride: 16\n",
      "Number of Input Channels: 4\n",
      "models have been loaded!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-2d205bc54661>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_val_result_with_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-42-e18b4f9a1740>\u001b[0m in \u001b[0;36mget_val_result_with_scaler\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mResume_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResume_box\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_re\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRefine_bbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_re\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox_re\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0msave_prediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResume_flag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResume_box\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthres\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepGrabCut_Davis_val/deeplab_resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_level_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupsample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bilinear'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_corners\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         return F.conv2d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 301\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "get_val_result_with_scaler(sample_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/ningxinL/model_zoo/DeepGrabCut/finetune_models_with_scaler/india_1/deepgc_epoch-11_davis_finetune.pth',\n",
       " 'india',\n",
       " '1']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
